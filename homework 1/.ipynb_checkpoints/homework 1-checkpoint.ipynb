{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50.040 Natural Language Processing (Summer 2019) Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your student ID(s) and name(s)**\n",
    "\n",
    "ID:\n",
    "\n",
    "Name:\n",
    "\n",
    "Students with whom you have discussed (if any):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Word embeddings are dense vectors that represent words, and capable of capturing semantic and syntactic similarity, relation with other words, etc.\n",
    "Word2Vec is one of the most popular techniques to learn word embeddings using shallow neural networks. It was developed by Tomas Mikolov in 2013 at Google.\n",
    "Generally, there are two methods to evaluate the quality of word embeddings. One is intrinsic evaluation, and the other is extrinsic evaluation. In intrinsic evaluation, the similarities between words are explored whereas in extrinsic evaluation, downstream tasks are executed based on word embeddings.\n",
    "\n",
    "In order to finish the following tasks, you need to [download](http://mattmahoney.net/dc/text8.zip) the text8 dataset and put it under the \"data\" folder. The text8 dataset consists of one single line of long text. Please do not change the data unless you are requested to do so.\n",
    "\n",
    "Environment:\n",
    "- Python 3.5 or above\n",
    "- gensim package\n",
    "- pytorch package\n",
    "- numpy package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "**(2 points) Consider a given sentence \"I am interested in NLP.\" If the window size is 1 (i.e., consider only the word to the left and to the right of the current word), what will be the context and target pairs in a CBOW model? What will be the pairs in a Skip-gram model?** (Images were taken from Mikolov's [paper](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"https://cdn-images-1.medium.com/max/800/1*UVe8b6CWYykcxbBOR6uCfg.png\"/> </td>\n",
    "<td> <img src=\"https://cdn-images-1.medium.com/max/800/1*SR6l59udY05_bUICAjb6-w.png\"  style=\"width: 250px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "### 1. Preprocess the dataset\n",
    "We will train our own word embedding on text8 dataset, the dataset contains **a single line of text**. Do not remove any characters from the data as it is very clean. We need to load and split the text into a sequence of words, then divide the words into batches to speed up training, each batch contains 100 words, please keep the orders of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the paths of the text dataset\n",
    "from nltk import word_tokenize\n",
    "text_path = 'data/text8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points) Complete the code of *read_tokenize_text*, which read a text file and tokenize it to words.** For example, a text \"I like NLP\" can be tokenized as \"I\", \"like\", \"NLP\". You can use either Python build-in function or tools like NLTK package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the text into memory, tokenize the text into words\n",
    "def read_tokenize_text(file_path):  \n",
    "    '''\n",
    "    Args:\n",
    "        file_path: the path of a text file, string\n",
    "    Return:\n",
    "        A sequence of words, Python list\n",
    "    '''\n",
    "    #to be completed\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points) Complete the code of *create_word_batch*, to divide a long sequence of words into batches of words.** For example, the word sequence [\"I\", \"like\", \"NLP\", \"So\", \"does\", \"he\"] can be divided into two batches, [\"I\", \"like\", \"NLP\"], [\"So\", \"does\", \"he\"]. It is more efficient to train word embedding on batches of word sequences rather than on a long sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the words into batches, each batch contains 100 words\n",
    "def create_word_batch(words, batch_size=100):\n",
    "    '''\n",
    "    Args:\n",
    "        words: a sequence of words, list\n",
    "        batch_size: the number of words in a batch, integer\n",
    "    Return:\n",
    "        batches of words, list\n",
    "    '''\n",
    "    #to be completed\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the functions above to read the text8 data, and create word batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = read_tokenize_text(text_path)\n",
    "print('Total number of words:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_words = create_word_batch(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(batch_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train our own word embeddings\n",
    "Instead of implementing a Word2vec model from scratch, we can use Python packages to achieve so by simply specifying inputs, hyperparameters in a package.\n",
    "\n",
    "In this exercise, we'll call [gensim](https://radimrehurek.com/gensim/models/word2vec.html) package to train word embeddings on *batch_words* sequences created above. If you are not familiar with gensim Word2Vec api, you can run \"help(Word2Vec)\" command in the cell or refer to the tutorial in the official website.\n",
    "\n",
    "Set the embedding size as 100, minimum count as 2, and select skip-gram approach. It may take minutes to complete the training. Set the other hyperparameters as default values or you can tune them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from time import time\n",
    "#help(Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points) Complete the code using gensim to train word embeddings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embedding trained successfully\n",
      "Timing:.80.36\n"
     ]
    }
   ],
   "source": [
    "#Use Word2Vec api to train word embedding\n",
    "start = time()\n",
    "#################to be completed################## \n",
    "model = None\n",
    "##################################################\n",
    "end = time()\n",
    "print('Word embedding trained successfully')\n",
    "print('Timing:.{:0.2f}s'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the embedding for the word \"car\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.wv['car']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualize the embeddings\n",
    "\n",
    "Visualization is often employed in analyzing word embedding. However, word embedding dimension is usually far larger than two, and it is not easy to visualize data that has more than 3 dimensions. We need to transform our word embeddings to 2-dimensional data before doing visualization.\n",
    "\n",
    "[Principal component analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables (entities each of which takes on various numerical values) into a set of values of linearly uncorrelated variables called principal components. PCA can be used to reduce dimension by selecting several principal components.\n",
    "\n",
    "In this exercise, we will use PCA to map the 100-dimensional word embeddings to 2-dimensional points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the size of vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135335"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then select first 300 words from the vocabulary in the model trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_words = list(model.wv.vocab.keys())\n",
    "select_300_words = vocab_words[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points) Complete the code to find the embedding of each word in select_300_words, and stack them into a numpy ndarray**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to be completed\n",
    "#shape of vectors should be 300*100\n",
    "vectors = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4 points) Complete PCA algorithm using Python numpy package from scratch.** PCA can be regarded as eigenvalue decomposition. Let's denote word embedding vectors as $X \\in R^{n \\times d}$, $n$ is word number, $d$ is embedding dimension. We will follow procedures described below and implement our PCA algorithm:\n",
    "- Compute the mean vector $\\overline X$ of the embedding vectors X.\n",
    "- Normalize embedding vectors by subtracting mean vector for each word embedding $X_i$.\n",
    "$$X_{i}=X_i-\\overline X$$\n",
    "- Compute the covariance matrix of normalized $X$\n",
    "$$C = \\frac {X^TX}{n-1}$$\n",
    "- Do eigen decomposition of the covariance matrix $C$ using numpy and get eigenvectors $W$(principal components).\n",
    "- Transform the normalized matrix $X$, and select first kth columns as projection.\n",
    "$$\\hat X = XW$$\n",
    "$$X_{proj} = \\hat X_{1:k}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#please use Python built-in function and numpy\n",
    "def pca(X, k=2):\n",
    "    '''\n",
    "    PCA algorithms\n",
    "    Args:\n",
    "        X: input matrix\n",
    "        k: number of principal components\n",
    "    Return:\n",
    "        the projections on the first k principal components\n",
    "    '''\n",
    "    ###################to be completed################\n",
    "    X_pca = None\n",
    "    ##################################################\n",
    "    return X_pca[:, :k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can project the 100-dimension word vectors to 2-dimension points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_d_embeddings = pca(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the projection of word embeddings on a 2-D plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualize the transformed word embeddings and annotate them with words.\n",
    "def plot(embeddings, labels):\n",
    "  assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "  plt.figure(figsize=(15,15))  # in inches\n",
    "  for i, label in enumerate(labels):\n",
    "    x, y = embeddings[i,:]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                   ha='right', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(two_d_embeddings, first_300_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points) Describe patterns in the visualization, are there any clusters of similar words? If there aren't any patterns, analyse the problem and re-train the word embeddings.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Intrinsic Evaluation\n",
    "**(2 points) Based on the embeddings we have trained, find most similar 5 words for each of the words [cat, dog, eat] and their similarities**, check whether the results match our tuition or not. You can use gensim functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##to be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular choice for intrinsic evaluation of word vectors is to explore the performance in completing word vector analogies, assume there are two word pairs, a:b, c:d, ideally, their embeddings satisfy a rule $x_a-x_b = x_c-x_d$. For instance, queen – king = actress – actor.\n",
    "\n",
    "**(2 points) Now find out which word will it be in woman - king = man - ?** You can use gensim package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##to be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extrinsic Evaluation\n",
    "Apart from intrinsic evaluation, the quality of word embeddings can also be evaluated by downstream tasks such as sentiment analysis, which aims to detect the sentiment polarity of a sentence. For instance, the sentence \"I like the movie very much\" is positive, whereas \"I was very disappointed with my new phone\" is negative.\n",
    "\n",
    "In sentiment analysis, each sentence can be tokenized as a sequence of words, then map each word to its embedding, next feed the sequence of word embedding to a GRU layer and obtain the final output of the GRU as the sentence vector. With the sentence vectors and labels, we can train a classifier.\n",
    "\n",
    "We will implement a sentiment analysis pipeline step by step on [movie reviews](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data) from the Rotten Tomatoes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Load the sentiment  dataset \n",
    "The dataset consists of training and testing parts, they have been preprocessed and saved in *.csv format. The data only has two sentiment labels, positive and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from dynamic_rnn import dynamicRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_split = pd.read_csv('data/train_data_processed.csv')\n",
    "test_data_split = pd.read_csv('data/test_data_processed.csv')\n",
    "train_data_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Transform texts into sequences of embedding\n",
    "We need to tokenize each sentence into a sequence of words first, then map them to a sequence of word embeddings. As the lengths of sentences vary, it is necessary to pad all the sentences to the same length in order to stack them in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize unknown word embedding\n",
    "unk_emb = np.random.rand(100) * 0.01- 0.005\n",
    "max_text_len = 52\n",
    "\n",
    "def word2emb(w):\n",
    "    '''\n",
    "    Map each word to a vector\n",
    "    Unknown word will be assigned a random value\n",
    "    Args:\n",
    "        w: a word, string\n",
    "    return:\n",
    "        embedding of the given word\n",
    "    '''\n",
    "    try:\n",
    "        emb = model.wv[w]\n",
    "    except:\n",
    "        emb = unk_emb \n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points) Complete the function *text2seq* below, we need a function to tokenize a sentence into a sequence of words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text2seq(text):\n",
    "    '''\n",
    "    Split a text into a sequence of words\n",
    "    Args:\n",
    "        text: a string of text\n",
    "    Return:\n",
    "        a list of words\n",
    "    '''\n",
    "    #to be completed\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points) Complete the function *seq2emb*, to map a sequence of words to a sequence of word embeddings**, remember to pad each sequence to the same length and return a numpy array.\n",
    "\n",
    "For example,  the lengths of the two sentences \"I like NLP\", \"It is a nice car\" are different, we can paddle the first one as \"I like NLP $\" by adding a special token \"$\" in the end. In the function seq2emb, you can just set the embeddings of the padded tokens as 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2emb(tokens, max_pad_length=52):\n",
    "    '''\n",
    "    Map a sequence of words to a sequence of embedding\n",
    "    Args:\n",
    "        tokens: a list of words, lengths may be varied\n",
    "        max_pad_length: the padding length, integer\n",
    "    Return:\n",
    "        a numpy.ndarray object, shape is max_pad_length*embedding_dim\n",
    "    '''\n",
    "    #to be completed \n",
    "    return None                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether our code works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = ['An', \"awesome\", \"car\"]\n",
    "example_seq_emb = seq2emb(tokens)\n",
    "assert example_seq_emb.shape == (52, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a function *text2emb*, to transform a batch of sentences to padded sequences of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text2emb(texts):\n",
    "    '''\n",
    "    Transform texts into sequences of embedding\n",
    "    Args:\n",
    "        texts: a list of sentences\n",
    "    Return:\n",
    "        sentence representations, sentence lengths\n",
    "    '''\n",
    "    text_seqs = list(map(text2seq, texts))\n",
    "    text_lens = np.array([len(seq) for seq in text_seqs])\n",
    "    text_seq_embs = list(map(seq2emb, text_seqs))#a list of tokens\n",
    "    text_seq_embs = np.stack(text_seq_embs, axis=0)\n",
    "    return text_seq_embs, text_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = ['This is an awesome car', 'I like NLP']\n",
    "example_text_seq_embs, example_text_lens = text2emb(texts)\n",
    "\n",
    "assert example_text_seq_embs.shape == (2, 52, 100)\n",
    "assert example_text_lens.shape == (2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 GRU-based Classifier\n",
    "Recurrent neural networks(RNN) have been explored in many NLP tasks, and proved to be efficient in capturing context dependencies. [Gated Recurrent Unit](https://en.wikipedia.org/wiki/Gated_recurrent_unit)(GRU)is a variant of Recurrent Neural Network(RNN). The GRU is similar to a long short-term memory (LSTM) with forget gate but has fewer parameters  as it lacks an output gate. The formula and architecture are shown below(taken from Wikipedia):\n",
    "![gru_formula](https://wikimedia.org/api/rest_v1/media/math/render/svg/d191eafc26594b0d9754f3221ca8a94852588f7c)\n",
    "![gru](https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Gated_Recurrent_Unit%2C_base_type.svg/220px-Gated_Recurrent_Unit%2C_base_type.svg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_t$ is the current input, $h_{t-1}$ is the last hidden output of GRU, $h_t$ is current hidden output of GRU. $z_t$ is the forget gate and $r_t$ is the reset gate, $W_z$, $W_r$, $U_z$, $U_r$ are parameters, $b_z$, $b_r$ are biases. \n",
    "\n",
    "We have provided a dynamic GRU class to handle varying-length sentences. Note, for this part, we need to use Pytorch package, if you are not familiar with Pytorch, you can refer to [tutorials](https://pytorch.org/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sentence can be transformed into a vector using an RNN layer, and we can handle a batch of sentences each time in our dynamic GRU class. Let's check our dynamic GRU class with examples created above. **Note, we need to feed both word embedding tensors of sentences and the actual lengths of sentences to dynamic GRU class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_dim, hidden_dim = 100, 16\n",
    "#Create a dynamic RNN object\n",
    "dynRNN = dynamicRNN(embed_dim, hidden_dim)\n",
    "#You need to transform numpy arrays to pytorch tensors, for integers, you need to use LongTensor type\n",
    "example_text_seq_embs = torch.FloatTensor(example_text_seq_embs)\n",
    "example_text_lens = torch.LongTensor(example_text_lens)\n",
    "#Obtain the sentence representations\n",
    "sent_reps = dynRNN(example_text_seq_embs, example_text_lens)\n",
    "print(sent_reps.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sent_reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4 points) Complete the forward function of RNNClassifier**, which input a tensor representing a batch of sentences as well as a tensor recording the actual lengths of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    '''\n",
    "    Transform sentence representations to sentiment label expression\n",
    "    '''\n",
    "    def __init__(self, embed_dim, hidden_dim, output_dim=2):\n",
    "        '''\n",
    "        Args:\n",
    "            embed_dim: embedding dimension, integer\n",
    "            hidden_dim: GRU hidden layer dimension, integer\n",
    "            output_dim: output dimension(label size), integer\n",
    "        '''\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.dynRNN = dynamicRNN(embed_dim, hidden_dim)\n",
    "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "     \n",
    "    def forward(self, text_seq_embs, text_seq_lens):\n",
    "        '''\n",
    "        Args:\n",
    "            text_seq_embs: batch sequences of word embedding, batch_size*sequence_length*embedding_dim\n",
    "            text_seq_lens: actual lengths of each batch sequence, batch_size\n",
    "        '''\n",
    "        ################to be completed##############\n",
    "        #1. Obtain the final hidden states for each sentences using dynamicRNN\n",
    "\n",
    "        #2. Use dropout on the sentence representations\n",
    "\n",
    "        #3. Feed the sentence vectors to a fully-connected layer\n",
    "\n",
    "        #4. Get and return the log softmax values of the output\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply check our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "classifier = RNNClassifier(100, 64)\n",
    "pred_scores = classifier(example_text_seq_embs, example_text_lens)\n",
    "assert pred_scores.size() == (2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the functions define above, you can transform the sentences in the dataset into sequences of embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process the training and testing sentences, obtain the padded sequences of embeddings and actual sentence lengths\n",
    "train_seq_embs, train_lens = text2emb(train_data_split.Phrase)\n",
    "test_seq_embs, test_lens = text2emb(test_data_split.Phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_data_split.Sentiment.values\n",
    "test_labels = test_data_split.Sentiment.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the parameters, optimization method and loss should be specified. Let's use Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "loss_func = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 point) Complete the code of training**. Note, we need to keep records of the average cost for each 40 loops for visualization. You can refer to a pytorch neural network [pipeline](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py). It is sufficient to run this code using CPU only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss 0.72\n",
      "Training Loss 0.66\n",
      "Training Loss 0.62\n",
      "Training Loss 0.51\n",
      "Training Loss 0.52\n",
      "Training Loss 0.57\n",
      "Training Loss 0.49\n",
      "Training Loss 0.46\n",
      "Training Loss 0.37\n",
      "Training Loss 0.40\n",
      "Training Loss 0.44\n",
      "Training Loss 0.47\n",
      "Training Loss 0.52\n",
      "Training Loss 0.42\n",
      "Training Loss 0.31\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "loops = 200\n",
    "batch_size = 64\n",
    "costs = []\n",
    "classifier.train()\n",
    "for i in range(epochs):\n",
    "    cost = 0\n",
    "    for j in range(loops):\n",
    "        classifier.zero_grad()\n",
    "        #Select a batch of training data\n",
    "        batch_index = np.random.choice(len(train_seq_embs), batch_size)\n",
    "        batch_text_reps, batch_lens = train_seq_embs[batch_index], train_lens[batch_index]\n",
    "        batch_labels = train_labels[batch_index]\n",
    "        \n",
    "        #transform the numpy array to pytorch tensor\n",
    "        batch_text_reps = torch.FloatTensor(batch_text_reps)\n",
    "        batch_lens = torch.LongTensor(batch_lens)\n",
    "        batch_labels = torch.LongTensor(batch_labels)\n",
    "        \n",
    "        ########to be completed##########\n",
    "        #compute the probability of output labels using your classifier\n",
    "        pred_probs = None\n",
    "        #compute loss\n",
    "        loss = None\n",
    "        \n",
    "        #backpropagate the gradient and update the weights using loss_func and optimizer\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cost += loss.item()\n",
    "        if j % 40 == 0:\n",
    "            if j>0:\n",
    "                costs.append(cost/40)\n",
    "            cost = 0\n",
    "            print('Training Loss {:.2f}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEICAYAAACuxNj9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(costs)), costs)\n",
    "plt.title('Average Loss of RNN Classifier')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can evaluate our classifier on the testing dataset with respect to accuracy. **We can fine tune the hyperparameters like epochs, learning rate, hidden size etc. to improve the performance.** The final accuracy should be above 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "test_seq_embs = torch.FloatTensor(test_seq_embs)\n",
    "test_lens = torch.LongTensor(test_lens)\n",
    "pred_probs = classifier(test_seq_embs, test_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_labels = pred_probs.argmax(1)\n",
    "accuracy = accuracy_score(test_labels, pred_labels)\n",
    "print('Testing Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! We have implemented a sentiment analysis pipeline successfully!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
